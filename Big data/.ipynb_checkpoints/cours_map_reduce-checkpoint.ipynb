{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ecc95080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from functools import reduce\n",
    "from itertools import chain\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19c9d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Raphaël\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ebee35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = np.arange(1,10,1)\n",
    "li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2ad85f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa64d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8550ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for x in li:\n",
    "    res.append(f(x))\n",
    "    \n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16a854",
   "metadata": {},
   "source": [
    "## map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9febc80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = list(map(f, li))\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfdd344",
   "metadata": {},
   "source": [
    "## reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d0c8d5",
   "metadata": {},
   "source": [
    "reduce va appliquer une fonction successivement sur un itérable, de manière récursive\n",
    "ici, on multipliera les termes successivement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7a694bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "li = list(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520c76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(i,j):\n",
    "    return i*j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a20988a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362880"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(f, li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741f3e07",
   "metadata": {},
   "source": [
    "## map/reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d149228c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def wordCount(text):\n",
    "    counts=defaultdict(int)\n",
    "    for word in text.split():\n",
    "        counts[word.lower()] +=1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e789e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = {\"./lot.txt\" : \"jour lève notre grisaille\"}\n",
    "D2 = {\"./lot.txt\" : \"trottoir notre ruelle notre tour\"}\n",
    "D3 = {\"./lot.txt\" : \"jour lève notre envie vous\"}\n",
    "D4 = {\"./lot.txt\" : \"faire comprendre tous notre tour\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a7512a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {'jour': 1, 'lève': 1, 'notre': 1, 'grisaille': 1})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordCount(D1[\"./lot.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a15cf0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map3(key,value):\n",
    "    \n",
    "    intermediate=[]\n",
    "    for word in value.split():\n",
    "        intermediate.append((word, 1))\n",
    "    return intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6706acfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(key, values):\n",
    "    \n",
    "    result = 0\n",
    "    for c in values:\n",
    "        result = result +c\n",
    "    return (key, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822e0f0c",
   "metadata": {},
   "source": [
    "## wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54915f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "parole = \"Le jour se lève sur notre grisaille, sur les trottoirs de nos ruelles et sur nos tours Le jour se lève sur notre envie de vous faire comprendre à tous que c'est à notre tour D'assumer nos rêves, d'en récolter la sève pour les graver dans chaque mur de pierre Le jour se lève et même si ça brûle les yeux, on ouvrira grand nos paupières Il a fait nuit trop longtemps et avancer sans lumière nous a souvent fait tâtonner Personne à pardonner, si on est là aujourd'hui c'est juste qu'on n'a pas abandonné On a cherché la lueur de l'aube en sachant qu'elle avait la couleur de l'espoir On s'est armé de nos stylos pour écrire nous-mêmes la suite de toute cette histoire\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d95d9d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords2 = stopwords.words('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ad0f03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split2(text):\n",
    "    '''Dans cette étape, on va spliter le fichier en 4 bloc ici, plusieurs étapes :\n",
    "    - mise en token du texte,\n",
    "    - resplit pour les apostrophes,\n",
    "    - transformation en 1 seule liste(2e niveau créé avec le 2e split),\n",
    "    - suppression des mots < 3 caractères,\n",
    "    - suppression des stopwords fr\n",
    "    - création dun dictionnaire avec les 4 splits'''\n",
    "    \n",
    "    # tokenisation\n",
    "    mots = word_tokenize(text)\n",
    "    mots = list(map((lambda x : x.split(\"'\")), mots))\n",
    "    mots = list(chain.from_iterable(mots))\n",
    "    mots = [mot for mot in mots if len(mot)>2]\n",
    "    mots = [mot.lower() for mot in mots if mot not in stopwords2]\n",
    "    \n",
    "    # splits\n",
    "    splits = {}\n",
    "    for i, split in enumerate(np.array_split(mots, 4)):\n",
    "        splits[f\"split_{i+1}\"] = list(split)\n",
    "        \n",
    "    return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9420bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map2(split):\n",
    "    '''creation dune liste qui créer un tuple (mot,1) pour chaque mot classé par ordre alphabétique,\n",
    "    un map sera fait pour chaque bloc'''\n",
    "    \n",
    "    return sorted([(mot, 1) for mot in split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e3254d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(compteur_mot):\n",
    "    '''création dun dictionnaire cle=mot et valeur=list(groupe avec les cle_valeur du mots)\n",
    "    creation dun autre dictionnaire qui recupere les valeur dans lautre dictionnaire et qui en fait une liste'''\n",
    "    \n",
    "    dict1 = {cle : list(groupe) for cle, groupe in groupby(compteur_mot, key=lambda x: x[0])}\n",
    "    \n",
    "    dict2 = {}\n",
    "    for cle, valeur in dict1.items():\n",
    "        dict2[cle] = []\n",
    "        for element in valeur:\n",
    "            dict2[cle].append(element[1])\n",
    "    return dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "58c8c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce2(dict2):\n",
    "    dict3 = {}\n",
    "    for cle, valeur in dict2.items():\n",
    "        dict3[cle] = sum(valeur)\n",
    "    return dict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b728480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    splits = split2(parole)\n",
    "    \n",
    "    cluster = []\n",
    "    \n",
    "    for split in splits.values():\n",
    "        cluster.append(map2(split))\n",
    "        \n",
    "    cluster = sorted(list(chain.from_iterable(cluster)))\n",
    "    \n",
    "    dict_shuffle = shuffle(cluster)\n",
    "    \n",
    "    reduce = reduce2(dict_shuffle)\n",
    "    \n",
    "    return reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e9af2bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abandonné': 1,\n",
       " 'armé': 1,\n",
       " 'assumer': 1,\n",
       " 'aube': 1,\n",
       " 'aujourd': 1,\n",
       " 'avancer': 1,\n",
       " 'brûle': 1,\n",
       " 'cette': 1,\n",
       " 'chaque': 1,\n",
       " 'cherché': 1,\n",
       " 'comprendre': 1,\n",
       " 'couleur': 1,\n",
       " 'envie': 1,\n",
       " 'espoir': 1,\n",
       " 'faire': 1,\n",
       " 'fait': 2,\n",
       " 'grand': 1,\n",
       " 'graver': 1,\n",
       " 'grisaille': 1,\n",
       " 'histoire': 1,\n",
       " 'hui': 1,\n",
       " 'jour': 3,\n",
       " 'juste': 1,\n",
       " 'longtemps': 1,\n",
       " 'lueur': 1,\n",
       " 'lumière': 1,\n",
       " 'lève': 3,\n",
       " 'mur': 1,\n",
       " 'nous-mêmes': 1,\n",
       " 'nuit': 1,\n",
       " 'ouvrira': 1,\n",
       " 'pardonner': 1,\n",
       " 'paupières': 1,\n",
       " 'personne': 1,\n",
       " 'pierre': 1,\n",
       " 'ruelles': 1,\n",
       " 'récolter': 1,\n",
       " 'rêves': 1,\n",
       " 'sachant': 1,\n",
       " 'sans': 1,\n",
       " 'souvent': 1,\n",
       " 'stylos': 1,\n",
       " 'suite': 1,\n",
       " 'sève': 1,\n",
       " 'tour': 1,\n",
       " 'tours': 1,\n",
       " 'tous': 1,\n",
       " 'toute': 1,\n",
       " 'trop': 1,\n",
       " 'trottoirs': 1,\n",
       " 'tâtonner': 1,\n",
       " 'yeux': 1,\n",
       " 'écrire': 1}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ca093",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
